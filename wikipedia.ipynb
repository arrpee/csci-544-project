{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8805397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sumy\n",
    "# %pip install matplotlib\n",
    "# %pip install gensim\n",
    "# %pip install num2words\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "\n",
    "import contractions\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from num2words import num2words\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc94fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread = [(toxicity, (words))]\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "data_path = 'data'\n",
    "conversations = [\n",
    "    'conversations-part1', \n",
    "    'conversations-part2',\n",
    "    'conversations-part3',\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "total_number_of_conversations = sum(\n",
    "    [len(os.listdir(os.path.join(data_path, conversation))) \n",
    "     for conversation in conversations])\n",
    "number_of_conversations = 0\n",
    "\n",
    "for conversation in conversations:\n",
    "    path = os.path.join(data_path, conversation)\n",
    "    for f in os.listdir(path):\n",
    "        true_path = os.path.join(path, f)\n",
    "        \n",
    "        c_df = pd.read_json(true_path, lines=True)\n",
    "        c_id = re.search('([0-9]+)', f).group(0)\n",
    "        c_thread = []\n",
    "        for t, c in zip(c_df['toxicity'], c_df['cleaned_content']):\n",
    "            c_thread.append((float(t), str(c)))\n",
    "        \n",
    "        df = pd.DataFrame({'id': c_id, 'thread': c_thread})\n",
    "        dfs.append(df)\n",
    "        \n",
    "        number_of_conversations += 1\n",
    "\n",
    "thread_dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e626360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "NUM_SENTENCES = 3\n",
    "\n",
    "tokenizer = Tokenizer(LANGUAGE)\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "summarizer = LuhnSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "def summarize_text(text: str) -> str:\n",
    "    if not text: return \"\"\n",
    "    parser = PlaintextParser.from_string(text, tokenizer)\n",
    "    return \"\".join([x._text for x in summarizer(parser.document, NUM_SENTENCES)])\n",
    "\n",
    "def numbers_to_words(text: str) -> str:\n",
    "    t = text.split()\n",
    "    for ind, word in enumerate(t):\n",
    "        if all(c.isdigit() for c in word):\n",
    "            t[ind] = num2words(word)\n",
    "        elif (\n",
    "            len(word) > 2\n",
    "            and all(c.isdigit() for c in word[:-2])\n",
    "            and word[-2:] in [\"st\", \"nd\", \"rd\", \"th\"]\n",
    "        ):\n",
    "            t[ind] = num2words(int(word[:-2]), to=\"ordinal\")\n",
    "\n",
    "    return \" \".join(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac731f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs = thread_dfs.groupby(['id'])['thread'].apply(list).reset_index()\n",
    "# let's sample .01% of the datasets for testing\n",
    "grouped_thread_dfs = grouped_thread_dfs.sample(frac=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877a4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "grouped_threads = []\n",
    "\n",
    "for thread in grouped_thread_dfs[\"thread\"]:\n",
    "    grouped_comments = []\n",
    "    \n",
    "    for comment in thread:\n",
    "        \n",
    "        stripped_comment = str(comment[1]).strip().lower()\n",
    "        no_http_comment = re.sub(r'\\s*https?://\\S+(\\s+|$)', '', stripped_comment)        \n",
    "        alphabetical_comment = re.sub(r'[^a-zA-Z\\s+]', '', no_http_comment)\n",
    "        whitespaced_comment = re.sub(r'\\s\\s+/g', ' ', alphabetical_comment)\n",
    "        expanded_comment = contractions.fix(whitespaced_comment)\n",
    "        tokenized_comment = word_tokenize(expanded_comment)\n",
    "            \n",
    "        grouped_comments.append(' '.join(tokenized_comment) + '.')\n",
    "\n",
    "    grouped_threads.append(' '.join(grouped_comments))\n",
    "\n",
    "grouped_thread_dfs['thread_text'] = grouped_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e68a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs[\"summary\"] = [summarize_text(text) for text in grouped_thread_dfs['thread_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e82fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels\n",
    "def calculate_overall_toxicity_boolean(thread):\n",
    "    if not thread: return 0\n",
    "    return sum([comment[0] for comment in thread])/len(thread) > .5\n",
    "\n",
    "def calculate_overall_toxicity_continuous(thread):\n",
    "    if not thread: return 0\n",
    "    return sum([comment[0] for comment in thread])/len(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce229eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs['toxicity'] = [calculate_overall_toxicity_boolean(thread) \n",
    "                                  for thread in grouped_thread_dfs['thread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e49f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grouped_thread_dfs[['toxicity', 'summary']]\n",
    "# of df == 1, select random == .3*len(df)\n",
    "# of df == 0, select random == .3*len(df)\n",
    "yes_toxic = df[df['toxicity'] == 1].sample(.02*len(df))\n",
    "no_toxic = df[df['toxicity'] == 0].sample(.02*len(df))\n",
    "balanced_df = pd.concat([yes_toxic, no_toxic])\n",
    "\n",
    "train_df = balanced_df.sample(frac=0.6, random_state=200)\n",
    "dev_df = balanced_df.drop(train_df.index).sample(frac=.5)\n",
    "test_df = balanced_df.drop(train_df.index).drop(dev_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c48795",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab79a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity : \n",
      "0.955090283353451\n",
      "0.9294933004774372\n"
     ]
    }
   ],
   "source": [
    "### Word2Vec\n",
    "def get_average_w2v_vector(row):\n",
    "    words = row[\"summary\"].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([word2vec[w] for w in words if w in word2vec], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    embedding = np.concatenate((avg_text_w2v), axis=None)\n",
    "    return embedding\n",
    "\n",
    "f1_scores = pd.DataFrame(columns=['Target Column', 'Dev Dataset F1', 'Test Dataset F1'])\n",
    "\n",
    "for target_col in [\"toxicity\",]:\n",
    "\n",
    "    train_X = train_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    dev_X = dev_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    test_X = test_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    print(f\"{target_col} : \")\n",
    "    \n",
    "    print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "    print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "    f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72208c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression:\n",
      "0.938262466759876\n",
      "0.9307862679955703\n",
      "TF-IDF Perceptron:\n",
      "0.9638968163808151\n",
      "0.935813953488372\n",
      "TF-IDF SDGClassifier:\n",
      "0.955090283353451\n",
      "0.9307862679955703\n"
     ]
    }
   ],
   "source": [
    "### TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_col = 'summary'\n",
    "target_col = 'toxicity'\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "transformer = vectorizer.fit_transform(train_df[train_col])\n",
    "\n",
    "train_X = vectorizer.transform(train_df[train_col])\n",
    "dev_X = vectorizer.transform(dev_df[train_col])\n",
    "test_X = vectorizer.transform(test_df[train_col])\n",
    "\n",
    "train_y = train_df[target_col]\n",
    "dev_y = dev_df[target_col]\n",
    "test_y = test_df[target_col]\n",
    "\n",
    "train_X = train_X[train_y.notna()]\n",
    "train_y = train_y[train_y.notna()]\n",
    "\n",
    "dev_X = dev_X[dev_y.notna()]\n",
    "dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "test_X = test_X[test_y.notna()]\n",
    "test_y = test_y[test_y.notna()]\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(transformer, train_df['toxicity'])\n",
    "\n",
    "pred_dev_y = clf.predict(dev_X)\n",
    "pred_test_y = clf.predict(test_X)\n",
    "\n",
    "print(\"TF-IDF Logistic Regression:\")\n",
    "print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n",
    "\n",
    "\n",
    "# Perceptron\n",
    "clf = Perceptron(max_iter=10000)\n",
    "clf.fit(transformer, train_df['toxicity'])\n",
    "\n",
    "pred_dev_y = clf.predict(dev_X)\n",
    "pred_test_y = clf.predict(test_X)\n",
    "\n",
    "print(\"TF-IDF Perceptron:\")\n",
    "print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n",
    "\n",
    "\n",
    "# SDGClassifier\n",
    "clf = SGDClassifier(max_iter=10000)\n",
    "clf.fit(transformer, train_df['toxicity'])\n",
    "\n",
    "pred_dev_y = clf.predict(dev_X)\n",
    "pred_test_y = clf.predict(test_X)\n",
    "\n",
    "print(\"TF-IDF SDGClassifier:\")\n",
    "print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ac6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs['toxicity'] = [calculate_overall_toxicity_continuous(thread) \n",
    "                                  for thread in grouped_thread_dfs['thread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75abc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2: 0.1588517053595372\n",
      "MLP Regressor:\n",
      "R^2: 0.0018399695738918753\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Continuous\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "train_col = 'summary'\n",
    "target_col = 'toxicity'\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "transformer = vectorizer.fit_transform(train_df[train_col])\n",
    "\n",
    "train_X = vectorizer.transform(train_df[train_col])\n",
    "dev_X = vectorizer.transform(dev_df[train_col])\n",
    "test_X = vectorizer.transform(test_df[train_col])\n",
    "\n",
    "train_y = train_df[target_col]\n",
    "dev_y = dev_df[target_col]\n",
    "test_y = test_df[target_col]\n",
    "\n",
    "train_X = train_X[train_y.notna()]\n",
    "train_y = train_y[train_y.notna()]\n",
    "\n",
    "dev_X = dev_X[dev_y.notna()]\n",
    "dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "test_X = test_X[test_y.notna()]\n",
    "test_y = test_y[test_y.notna()]\n",
    "\n",
    "# Linear Regression\n",
    "clf = LinearRegression()\n",
    "clf.fit(train_X, train_df[target_col])\n",
    "print(\"Linear Regression:\")\n",
    "print(f'R^2: {clf.score(dev_X, dev_y)}')\n",
    "\n",
    "# Perceptron\n",
    "clf = MLPRegressor()\n",
    "clf.fit(train_X, train_df[target_col])\n",
    "print(\"MLP Regressor:\")\n",
    "print(f'R^2: {clf.score(dev_X, dev_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b2dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install sentencepiece\n",
    "\n",
    "# BART\n",
    "from transformers import pipeline\n",
    "\n",
    "bart = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text_with_bart(text: str) -> str:\n",
    "    if not text: return \"\"\n",
    "    try:\n",
    "        summary_list = bart(text, max_length=10000, min_length=1, do_sample=False)\n",
    "        return summary_list[0]['summary_text']\n",
    "    except:\n",
    "        return \"\"\n",
    "        \n",
    "\n",
    "# T5\n",
    "# https://towardsdatascience.com/simple-abstractive-text-summarization-with-pretrained-t5-text-to-text-transfer-transformer-10f6d602c426\n",
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "def summarize_text_with_t5(text: str) -> str:\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                 num_beams=4,\n",
    "                                 no_repeat_ngram_size=2,\n",
    "                                 min_length=1,\n",
    "                                 max_length=10000,\n",
    "                                 early_stopping=True)\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88586",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs['summary_bart'] = [summarize_text_with_bart(text) for text in grouped_thread_dfs['thread_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2Vec\n",
    "def get_average_w2v_vector(row, col):\n",
    "    words = row[col].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([word2vec[w] for w in words if w in word2vec], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    embedding = np.concatenate((avg_text_w2v), axis=None)\n",
    "    return embedding\n",
    "\n",
    "f1_scores = pd.DataFrame(columns=['Target Column', 'Dev Dataset F1', 'Test Dataset F1'])\n",
    "\n",
    "for target_col in [\"toxicity\",]:\n",
    "\n",
    "    train_X = train_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_bart\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    dev_X = dev_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_bart\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    test_X = test_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_bart\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    print(f\"{target_col} : \")\n",
    "    \n",
    "    print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "    print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "    f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_thread_dfs['summary_t5'] = [summarize_text_with_t5(text) for text in grouped_thread_dfs['thread_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c571f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2Vec\n",
    "def get_average_w2v_vector(row, col):\n",
    "    words = row[col].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([word2vec[w] for w in words if w in word2vec], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    embedding = np.concatenate((avg_text_w2v), axis=None)\n",
    "    return embedding\n",
    "\n",
    "f1_scores = pd.DataFrame(columns=['Target Column', 'Dev Dataset F1', 'Test Dataset F1'])\n",
    "\n",
    "for target_col in [\"toxicity\",]:\n",
    "\n",
    "    train_X = train_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_t5\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    dev_X = dev_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_t5\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    test_X = test_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x, \"summary_t5\"), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    print(f\"{target_col} : \")\n",
    "    \n",
    "    print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "    print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "    f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b12c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
