{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% processed.\n",
      "10% processed.\n",
      "20% processed.\n",
      "30% processed.\n",
      "40% processed.\n",
      "50% processed.\n",
      "60% processed.\n",
      "70% processed.\n",
      "80% processed.\n",
      "90% processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "data_path = 'data'\n",
    "conversations = [\n",
    "    'conversations-part1', \n",
    "    'conversations-part2',\n",
    "    'conversations-part3',\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "total_number_of_conversations = sum(\n",
    "    [len(os.listdir(os.path.join(data_path, conversation))) \n",
    "     for conversation in conversations])\n",
    "number_of_conversations = 0\n",
    "increment = 0\n",
    "\n",
    "for conversation in conversations:\n",
    "    path = os.path.join(data_path, conversation)\n",
    "    for f in os.listdir(path):\n",
    "        \n",
    "        percent = (\n",
    "            (number_of_conversations/total_number_of_conversations)*100\n",
    "        )\n",
    "        \n",
    "        if percent/10 >= increment:\n",
    "            print(f'{increment*10}% processed.')\n",
    "            increment += 1\n",
    "        \n",
    "        true_path = os.path.join(path, f)\n",
    "        \n",
    "        c_df = pd.read_json(true_path, lines=True)\n",
    "        c_id = re.search('([0-9]+)', f).group(0)\n",
    "        c_thread = []\n",
    "        for t, c in zip(c_df['toxicity'], c_df['cleaned_content']):\n",
    "            c_thread.append((float(t), str(c)))\n",
    "        \n",
    "        df = pd.DataFrame({'id': c_id, 'thread': c_thread})\n",
    "        dfs.append(df)\n",
    "        \n",
    "        number_of_conversations += 1\n",
    "\n",
    "full_wikipedia_df = pd.concat(dfs)\n",
    "full_wikipedia_df = full_wikipedia_df.groupby(['id'])['thread'].apply(list).reset_index()\n",
    "# sample .1 of the datasets\n",
    "wikipedia_df = full_wikipedia_df.sample(frac=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 50% of the dataset\n",
    "wikipedia_df = full_wikipedia_df.sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96634, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99064</th>\n",
       "      <td>383017989</td>\n",
       "      <td>[(0.1134071,  Sorting by language rather than by country ), (0.05908121, It seems rather strange to me that the different sections are named and sorted by country. More often than not, notation and pronunciation of times is tied to the language, not to the country. Differences in customs between two countries speaking the same language are usually much smaller than those between two different languages (whether in the same country or not). Case in point would be the usage in East Africa, which is strongly language-dependent as is mentioned in the article. So I think the article should sort by language, and subsections should be created where norms differ in different countries speaking the same language (i.e. English in the UK versus English in the US).  ), (0.0440167, \"More often than not, notation and pronunciation of times is tied to the language.\" Are you sure? What is your evidence for that? I would rather guess the opposite, since formats are often standardized by the STATE b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192042</th>\n",
       "      <td>96771021</td>\n",
       "      <td>[(0.04421617,  History of the States of Jersey ), (0.05053069, Have added in the History of the States of Jersey from its origins as a small part of the Royal Court, don't think the history section as it was really did it's job!\\nI have taken out certain further sections relating to specific politicians and their activities outside the States of Jersey. Hope this is an improvement.), (0.05941844, Have added in the History of the States of Jersey from its origins as a small part of the Royal Court, don't think the history section as it was really did it's job!\\nI have taken out certain further sections relating to specific politicians and their activities outside the States of Jersey. Hope this is an improvement.\\nDarius)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108179</th>\n",
       "      <td>414654877</td>\n",
       "      <td>[(0.01145369,  Vegas ), (0.06575359, Guys, the source which adds Cunningham's limited schedule mentioned Vegas, thus adding Vegas makes sense, seeing as there's nothing saying to the contrary as of yet? Several other sites which report on it also mention Vegas as well - although while that may be simply as they all reported from a press release, it still shows that they know something that probably hasn't yet been publicly announced for a reason. '''''' •), (0.04667206, There are speculations about Las Vegas for a long time. But we have to wait until an official announcement is made. There would be a reason why here stand TBA on October 16.  ), (0.0581587, I'm well aware that it has officially been TBA since the announcement of the schedule last year. However, as it stands, this is the first source which has concretely mentioned anything with regards to the eventual decision as to whether it is Vegas or California. Another thing to note is that the report doesn't even have a hint o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>101729823</td>\n",
       "      <td>[(0.01805616, language articles), (0.03854093, 'nuff said, but can be titled either in native language (St'at'imcets) or in the form Shuswap language; Wiki guidelines, it should be stressed, prefer the latter (use English, which is the language of the encyclopedia...).  Some ethno and gov articles will have more than one language listed in their cats; some languages span more than one gov group, or in the case of the Sto:lo and Chehalis, two different ones.  Cats for this are specialized in the linguistics hierarchy (examples later), but they should generally all take the relevant nation-category if there is one Category:Secwepemc, Category:Stó:lō, Category:Syilx etc.), (0.03854093, 'nuff said, but can be titled either in native language (St'at'imcets) or in the form Shuswap language; Wiki guidelines, it should be stressed, prefer the latter (use English, which is the language of the encyclopedia...).  Some ethno and gov articles will have more than one language listed in their cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174752</th>\n",
       "      <td>672352256</td>\n",
       "      <td>[(0.0401642,  ), (0.08465946, Templates like these should not be viewable to the reader.  Example templates are ,  and .  You will also need to add a date parameter, a category and some information on the template page.  Pinging  and  as they are template editors, so they can help.\\nIn addition, you messed up a reference in Analytic dissection when you converted to a different reference format... you half deleted one.   ), (0.06495479, ,  is an example of a visible article template on referencing,  is similar. Also, it may be a good idea to program bots to ignore pages that have the BBStyle template in place. It would cut down on work that editors have to clear up after the bot visits. Thanks,  ), (0.03428813,   is only on five articles and it too should be hidden.  ,  and  also do not show it to the reader.  However, these three are hardly used too.   Regardless, the template should only be seen by the editor.  Please hide the notice from the reader.   All examples I've given use ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  \\\n",
       "99064   383017989   \n",
       "192042   96771021   \n",
       "108179  414654877   \n",
       "637     101729823   \n",
       "174752  672352256   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         thread  \n",
       "99064   [(0.1134071,  Sorting by language rather than by country ), (0.05908121, It seems rather strange to me that the different sections are named and sorted by country. More often than not, notation and pronunciation of times is tied to the language, not to the country. Differences in customs between two countries speaking the same language are usually much smaller than those between two different languages (whether in the same country or not). Case in point would be the usage in East Africa, which is strongly language-dependent as is mentioned in the article. So I think the article should sort by language, and subsections should be created where norms differ in different countries speaking the same language (i.e. English in the UK versus English in the US).  ), (0.0440167, \"More often than not, notation and pronunciation of times is tied to the language.\" Are you sure? What is your evidence for that? I would rather guess the opposite, since formats are often standardized by the STATE b...  \n",
       "192042                                                                                                                                                                                                                                                                              [(0.04421617,  History of the States of Jersey ), (0.05053069, Have added in the History of the States of Jersey from its origins as a small part of the Royal Court, don't think the history section as it was really did it's job!\\nI have taken out certain further sections relating to specific politicians and their activities outside the States of Jersey. Hope this is an improvement.), (0.05941844, Have added in the History of the States of Jersey from its origins as a small part of the Royal Court, don't think the history section as it was really did it's job!\\nI have taken out certain further sections relating to specific politicians and their activities outside the States of Jersey. Hope this is an improvement.\\nDarius)]  \n",
       "108179  [(0.01145369,  Vegas ), (0.06575359, Guys, the source which adds Cunningham's limited schedule mentioned Vegas, thus adding Vegas makes sense, seeing as there's nothing saying to the contrary as of yet? Several other sites which report on it also mention Vegas as well - although while that may be simply as they all reported from a press release, it still shows that they know something that probably hasn't yet been publicly announced for a reason. '''''' •), (0.04667206, There are speculations about Las Vegas for a long time. But we have to wait until an official announcement is made. There would be a reason why here stand TBA on October 16.  ), (0.0581587, I'm well aware that it has officially been TBA since the announcement of the schedule last year. However, as it stands, this is the first source which has concretely mentioned anything with regards to the eventual decision as to whether it is Vegas or California. Another thing to note is that the report doesn't even have a hint o...  \n",
       "637     [(0.01805616, language articles), (0.03854093, 'nuff said, but can be titled either in native language (St'at'imcets) or in the form Shuswap language; Wiki guidelines, it should be stressed, prefer the latter (use English, which is the language of the encyclopedia...).  Some ethno and gov articles will have more than one language listed in their cats; some languages span more than one gov group, or in the case of the Sto:lo and Chehalis, two different ones.  Cats for this are specialized in the linguistics hierarchy (examples later), but they should generally all take the relevant nation-category if there is one Category:Secwepemc, Category:Stó:lō, Category:Syilx etc.), (0.03854093, 'nuff said, but can be titled either in native language (St'at'imcets) or in the form Shuswap language; Wiki guidelines, it should be stressed, prefer the latter (use English, which is the language of the encyclopedia...).  Some ethno and gov articles will have more than one language listed in their cat...  \n",
       "174752  [(0.0401642,  ), (0.08465946, Templates like these should not be viewable to the reader.  Example templates are ,  and .  You will also need to add a date parameter, a category and some information on the template page.  Pinging  and  as they are template editors, so they can help.\\nIn addition, you messed up a reference in Analytic dissection when you converted to a different reference format... you half deleted one.   ), (0.06495479, ,  is an example of a visible article template on referencing,  is similar. Also, it may be a good idea to program bots to ignore pages that have the BBStyle template in place. It would cut down on work that editors have to clear up after the bot visits. Thanks,  ), (0.03428813,   is only on five articles and it too should be hidden.  ,  and  also do not show it to the reader.  However, these three are hardly used too.   Regardless, the template should only be seen by the editor.  Please hide the notice from the reader.   All examples I've given use ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wikipedia_df.shape)\n",
    "wikipedia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the comment threads at each comment level in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from num2words import num2words\n",
    "\n",
    "def numbers_to_words(text: str) -> str:\n",
    "    t = text.split()\n",
    "    for ind, word in enumerate(t):\n",
    "        if all(c.isdigit() for c in word):\n",
    "            t[ind] = num2words(word)\n",
    "        elif (\n",
    "            len(word) > 2\n",
    "            and all(c.isdigit() for c in word[:-2])\n",
    "            and word[-2:] in [\"st\", \"nd\", \"rd\", \"th\"]\n",
    "        ):\n",
    "            t[ind] = num2words(int(word[:-2]), to=\"ordinal\")\n",
    "\n",
    "    return \" \".join(t)\n",
    "\n",
    "grouped_threads = []\n",
    "\n",
    "for thread in wikipedia_df[\"thread\"]:\n",
    "    grouped_comments = []\n",
    "    \n",
    "    for comment in thread:\n",
    "        \n",
    "        stripped_comment = str(comment[1]).strip().lower()\n",
    "        no_http_comment = re.sub(r'\\s*https?://\\S+(\\s+|$)', '', stripped_comment)        \n",
    "        alphabetical_comment = re.sub(r'[^a-zA-Z\\s+]', '', no_http_comment)\n",
    "        whitespaced_comment = re.sub(r'\\s\\s+/g', ' ', alphabetical_comment)\n",
    "        expanded_comment = contractions.fix(whitespaced_comment)\n",
    "        tokenized_comment = word_tokenize(expanded_comment)\n",
    "            \n",
    "        grouped_comments.append(' '.join(tokenized_comment) + '.')\n",
    "\n",
    "    grouped_threads.append(' '.join(grouped_comments))\n",
    "\n",
    "wikipedia_df['text'] = grouped_threads\n",
    "\n",
    "def calculate_overall_toxicity_boolean(thread):\n",
    "    if not thread: return 0\n",
    "    return sum([comment[0] for comment in thread])/len(thread) > .5\n",
    "\n",
    "def calculate_overall_toxicity_continuous(thread):\n",
    "    if not thread: return 0\n",
    "    return sum([comment[0] for comment in thread])/len(thread)\n",
    "\n",
    "wikipedia_df['toxicity_bool'] = [calculate_overall_toxicity_boolean(thread) \n",
    "                                 for thread in wikipedia_df['thread']]\n",
    "\n",
    "wikipedia_df['toxicity_cont'] = [calculate_overall_toxicity_continuous(thread) \n",
    "                                 for thread in wikipedia_df['thread']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wikipedia_df[['toxicity_bool', 'toxicity_cont', 'text']]\n",
    "\n",
    "yes_toxic = df[df['toxicity_bool'] == 1].sample(2_000)\n",
    "no_toxic = df[df['toxicity_bool'] == 0].sample(2_000)\n",
    "balanced_df = pd.concat([yes_toxic, no_toxic])\n",
    "\n",
    "train_df = balanced_df.sample(frac=0.6, random_state=200)\n",
    "dev_df = balanced_df.drop(train_df.index).sample(frac=.5)\n",
    "test_df = balanced_df.drop(train_df.index).drop(dev_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = [\n",
    "    [\"toxicity_cont\", \"Toxicity\"]\n",
    "]\n",
    "\n",
    "for column_name, display_name in cols:\n",
    "    s = pd.Series(wikipedia_df[column_name])\n",
    "    ax = s.plot.density()\n",
    "    ax.set(ylabel=\"Frequency\", xlabel=display_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, dev_df, test_df]:\n",
    "    df['toxicity'] = df['toxicity_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Dev F1  Test F1\n",
       "0  Toxicity    0.86     0.88"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_w2v_vector(row):\n",
    "    words = row[\"text\"].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([w2v_model[w] for w in words if w in w2v_model], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    return avg_text_w2v\n",
    "\n",
    "\n",
    "baseline_scores = pd.DataFrame(columns=[\"Dataset\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "for target_col, display_name in [\n",
    "    (\"toxicity\", \"Toxicity\"),\n",
    "]:\n",
    "    train_X = train_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    dev_X = dev_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    test_X = test_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "        display_name,\n",
    "        f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "        f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model with Extractive Summary Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer:\n",
    "    def __init__(self) -> None:\n",
    "        self.language = \"english\"\n",
    "        self.num_sentences = 3\n",
    "        self.tokenizer = Tokenizer(self.language)\n",
    "        self.stemmer = Stemmer(self.language)\n",
    "\n",
    "    def summarize(self, thread: str) -> str:\n",
    "        parser = PlaintextParser.from_string(thread, self.tokenizer)\n",
    "        return \"\".join(\n",
    "            (x._text for x in self.summarizer(parser.document, self.num_sentences))\n",
    "        )\n",
    "\n",
    "\n",
    "class Luhn(Summarizer):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.summarizer = LuhnSummarizer()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Luhn\"\n",
    "\n",
    "\n",
    "class LSA(Summarizer):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.summarizer = LsaSummarizer()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"LSA\"\n",
    "\n",
    "\n",
    "class LexRank(Summarizer):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.summarizer = LexRankSummarizer()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"LexRank\"\n",
    "\n",
    "\n",
    "class TextRank(Summarizer):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.summarizer = TextRankSummarizer()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"TextRank\"\n",
    "\n",
    "\n",
    "summarizer_models = [Luhn(), LSA(), LexRank(), TextRank()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (6) is lower than number of sentences (839). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (4) is lower than number of sentences (6). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (3) is lower than number of sentences (4). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1) is lower than number of sentences (2). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summarizer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luhn</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSA</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summarizer    Target  Dev F1  Test F1\n",
       "0       Luhn  Toxicity    0.84     0.86\n",
       "1        LSA  Toxicity    0.85     0.86\n",
       "2    LexRank  Toxicity    0.84     0.85\n",
       "3   TextRank  Toxicity    0.85     0.85"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Summarizer\", \"Target\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "\n",
    "for summarizer in summarizer_models:\n",
    "    train_df[\"summary\"] = train_df[\"text\"].apply(summarizer.summarize)\n",
    "    dev_df[\"summary\"] = dev_df[\"text\"].apply(summarizer.summarize)\n",
    "    test_df[\"summary\"] = test_df[\"text\"].apply(summarizer.summarize)\n",
    "\n",
    "    for target_col, display_name in [\n",
    "        (\"toxicity\", \"Toxicity\"),\n",
    "    ]:\n",
    "\n",
    "\n",
    "        vectorizer = CountVectorizer()\n",
    "        train_X = vectorizer.fit_transform(train_df[\"summary\"])\n",
    "        dev_X = vectorizer.transform(dev_df[\"summary\"])\n",
    "        test_X = vectorizer.transform(test_df[\"summary\"])\n",
    "\n",
    "        train_y = train_df[target_col]\n",
    "        dev_y = dev_df[target_col]\n",
    "        test_y = test_df[target_col]\n",
    "\n",
    "        train_X = train_X[train_y.notna()]\n",
    "        train_y = train_y[train_y.notna()]\n",
    "\n",
    "        dev_X = dev_X[dev_y.notna()]\n",
    "        dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "        test_X = test_X[test_y.notna()]\n",
    "        test_y = test_y[test_y.notna()]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred_dev_y = clf.predict(dev_X)\n",
    "        pred_test_y = clf.predict(test_X)\n",
    "\n",
    "        baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "            str(summarizer),\n",
    "            display_name,\n",
    "            f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "            f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "        ]\n",
    "\n",
    "    train_df = train_df.drop([\"summary\"], axis=1)\n",
    "    dev_df = dev_df.drop([\"summary\"], axis=1)\n",
    "    test_df = test_df.drop([\"summary\"], axis=1)\n",
    "\n",
    "\n",
    "baseline_scores.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (6) is lower than number of sentences (839). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (4) is lower than number of sentences (6). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (3) is lower than number of sentences (4). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1) is lower than number of sentences (2). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summarizer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luhn</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSA</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summarizer    Target  Dev F1  Test F1\n",
       "0       Luhn  Toxicity    0.85     0.86\n",
       "1        LSA  Toxicity    0.85     0.86\n",
       "2    LexRank  Toxicity    0.86     0.85\n",
       "3   TextRank  Toxicity    0.85     0.86"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Summarizer\", \"Target\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "\n",
    "for summarizer in summarizer_models:\n",
    "    train_df[\"summary\"] = train_df[\"text\"].apply(summarizer.summarize)\n",
    "    dev_df[\"summary\"] = dev_df[\"text\"].apply(summarizer.summarize)\n",
    "    test_df[\"summary\"] = test_df[\"text\"].apply(summarizer.summarize)\n",
    "\n",
    "    for target_col, display_name in [\n",
    "        (\"toxicity\", \"Toxicity\"),\n",
    "    ]:\n",
    "\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        train_X = vectorizer.fit_transform(train_df[\"summary\"])\n",
    "        dev_X = vectorizer.transform(dev_df[\"summary\"])\n",
    "        test_X = vectorizer.transform(test_df[\"summary\"])\n",
    "\n",
    "        train_y = train_df[target_col]\n",
    "        dev_y = dev_df[target_col]\n",
    "        test_y = test_df[target_col]\n",
    "\n",
    "        train_X = train_X[train_y.notna()]\n",
    "        train_y = train_y[train_y.notna()]\n",
    "\n",
    "        dev_X = dev_X[dev_y.notna()]\n",
    "        dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "        test_X = test_X[test_y.notna()]\n",
    "        test_y = test_y[test_y.notna()]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred_dev_y = clf.predict(dev_X)\n",
    "        pred_test_y = clf.predict(test_X)\n",
    "\n",
    "        baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "            str(summarizer),\n",
    "            display_name,\n",
    "            f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "            f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "        ]\n",
    "\n",
    "    train_df = train_df.drop([\"summary\"], axis=1)\n",
    "    dev_df = dev_df.drop([\"summary\"], axis=1)\n",
    "    test_df = test_df.drop([\"summary\"], axis=1)\n",
    "\n",
    "\n",
    "baseline_scores.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (6) is lower than number of sentences (839). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (4) is lower than number of sentences (6). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (3) is lower than number of sentences (4). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1) is lower than number of sentences (2). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summarizer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luhn</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSA</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summarizer    Target  Dev F1  Test F1\n",
       "0       Luhn  Toxicity    0.86     0.88\n",
       "1        LSA  Toxicity    0.87     0.89\n",
       "2    LexRank  Toxicity    0.87     0.89\n",
       "3   TextRank  Toxicity    0.86     0.88"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_w2v_vector_thread(row):\n",
    "    words = row[\"text\"].split()\n",
    "    summary_words = row[\"summary\"].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([w2v_model[w] for w in words if w in w2v_model], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    avg_thread_w2v = np.sum(\n",
    "        [w2v_model[w] for w in summary_words if w in w2v_model], axis=0\n",
    "    ) / (len(summary_words) if summary_words else 1)\n",
    "\n",
    "    if avg_thread_w2v.shape != (300,):\n",
    "        avg_thread_w2v = np.zeros((300,))\n",
    "\n",
    "    embedding = np.concatenate((avg_text_w2v, avg_thread_w2v), axis=None)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "baseline_scores = pd.DataFrame(columns=[\"Summarizer\", \"Target\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "\n",
    "for summarizer in summarizer_models:\n",
    "    train_df[\"summary\"] = train_df[\"text\"].apply(summarizer.summarize)\n",
    "    dev_df[\"summary\"] = dev_df[\"text\"].apply(summarizer.summarize)\n",
    "    test_df[\"summary\"] = test_df[\"text\"].apply(summarizer.summarize)\n",
    "\n",
    "    for target_col, display_name in [\n",
    "        (\"toxicity\", \"Toxicity\"),\n",
    "    ]:\n",
    "        train_X = train_df.apply(\n",
    "            lambda x: get_average_w2v_vector_thread(x), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "        dev_X = dev_df.apply(\n",
    "            lambda x: get_average_w2v_vector_thread(x), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "        test_X = test_df.apply(\n",
    "            lambda x: get_average_w2v_vector_thread(x), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        train_y = train_df[target_col]\n",
    "        dev_y = dev_df[target_col]\n",
    "        test_y = test_df[target_col]\n",
    "\n",
    "        train_X = train_X[train_y.notna()]\n",
    "        train_y = train_y[train_y.notna()]\n",
    "\n",
    "        dev_X = dev_X[dev_y.notna()]\n",
    "        dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "        test_X = test_X[test_y.notna()]\n",
    "        test_y = test_y[test_y.notna()]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred_dev_y = clf.predict(dev_X)\n",
    "        pred_test_y = clf.predict(test_X)\n",
    "\n",
    "        baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "            str(summarizer),\n",
    "            display_name,\n",
    "            f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "            f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "        ]\n",
    "\n",
    "    train_df = train_df.drop([\"summary\"], axis=1)\n",
    "    dev_df = dev_df.drop([\"summary\"], axis=1)\n",
    "    test_df = test_df.drop([\"summary\"], axis=1)\n",
    "\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with sentence embedding features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.0-cp310-none-macosx_11_0_arm64.whl (55.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.23.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.9.0)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 kB\u001b[0m \u001b[31m387.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.8.17)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-macosx_12_0_arm64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m916.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=c92beea48b2e9282e011918d75afe9f23c7b9f1fe23d7edc2b5c8cb12a94fe8a\n",
      "  Stored in directory: /Users/kevinsun/Library/Caches/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, typing-extensions, pyyaml, filelock, torch, huggingface-hub, transformers, torchvision, sentence-transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.11.1 pyyaml-6.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.0 torchvision-0.14.0 transformers-4.25.1 typing-extensions-4.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert_model = SentenceTransformer(\"stsb-distilroberta-base-v2\")\n",
    "\n",
    "train_sentence_embeddings = {}\n",
    "dev_entence_embeddings = {}\n",
    "test_sentence_embeddings = {}\n",
    "\n",
    "train_sentence_embeddings[\"Base\"] = sbert_model.encode(train_df[\"text\"].to_list())\n",
    "dev_entence_embeddings[\"Base\"] = sbert_model.encode(dev_df[\"text\"].to_list())\n",
    "test_sentence_embeddings[\"Base\"] = sbert_model.encode(test_df[\"text\"].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (6) is lower than number of sentences (839). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (4) is lower than number of sentences (6). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (3) is lower than number of sentences (4). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1) is lower than number of sentences (2). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n"
     ]
    }
   ],
   "source": [
    "for summarizer in summarizer_models:\n",
    "    train_sentence_embeddings[str(summarizer)] = sbert_model.encode(\n",
    "        train_df[\"text\"].apply(summarizer.summarize).to_list()\n",
    "    )\n",
    "    dev_entence_embeddings[str(summarizer)] = sbert_model.encode(\n",
    "        dev_df[\"text\"].apply(summarizer.summarize).to_list()\n",
    "    )\n",
    "    test_sentence_embeddings[str(summarizer)] = sbert_model.encode(\n",
    "        test_df[\"text\"].apply(summarizer.summarize).to_list()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Dev F1  Test F1\n",
       "0  Toxicity    0.89     0.87"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Dataset\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "\n",
    "for target_col, display_name in [\n",
    "    (\"toxicity\", \"Toxicity\"),\n",
    "]:\n",
    "    train_X = train_sentence_embeddings[\"Base\"].copy()\n",
    "    dev_X = dev_entence_embeddings[\"Base\"].copy()\n",
    "    test_X = test_sentence_embeddings[\"Base\"].copy()\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "        display_name,\n",
    "        f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "        f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summarizer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luhn</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSA</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summarizer    Target  Dev F1  Test F1\n",
       "0       Luhn  Toxicity    0.87     0.87\n",
       "1        LSA  Toxicity    0.87     0.87\n",
       "2    LexRank  Toxicity    0.88     0.87\n",
       "3   TextRank  Toxicity    0.87     0.86"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Summarizer\", \"Target\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "for summarizer in summarizer_models:\n",
    "    for target_col, display_name in [\n",
    "        (\"toxicity\", \"Toxicity\"),\n",
    "    ]:\n",
    "        train_X = np.concatenate(\n",
    "            (\n",
    "                train_sentence_embeddings[\"Base\"],\n",
    "                train_sentence_embeddings[str(summarizer)],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        dev_X = np.concatenate(\n",
    "            (dev_entence_embeddings[\"Base\"], dev_entence_embeddings[str(summarizer)]),\n",
    "            axis=1,\n",
    "        )\n",
    "        test_X = np.concatenate(\n",
    "            (\n",
    "                test_sentence_embeddings[\"Base\"],\n",
    "                test_sentence_embeddings[str(summarizer)],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        train_y = train_df[target_col]\n",
    "        dev_y = dev_df[target_col]\n",
    "        test_y = test_df[target_col]\n",
    "\n",
    "        train_X = train_X[train_y.notna()]\n",
    "        train_y = train_y[train_y.notna()]\n",
    "\n",
    "        dev_X = dev_X[dev_y.notna()]\n",
    "        dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "        test_X = test_X[test_y.notna()]\n",
    "        test_y = test_y[test_y.notna()]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred_dev_y = clf.predict(dev_X)\n",
    "        pred_test_y = clf.predict(test_X)\n",
    "\n",
    "        baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "            str(summarizer),\n",
    "            display_name,\n",
    "            f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "            f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "        ]\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out a better classification models with sentence embeddings features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.1-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from xgboost) (1.9.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from xgboost) (1.23.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Dev F1  Test F1\n",
       "0  Toxicity    0.89     0.89"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Dataset\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "enc = LabelEncoder()\n",
    "\n",
    "for target_col, display_name in [\n",
    "    (\"toxicity\", \"Toxicity\"),\n",
    "]:\n",
    "    train_X = train_sentence_embeddings[\"Base\"].copy()\n",
    "    dev_X = dev_entence_embeddings[\"Base\"].copy()\n",
    "    test_X = test_sentence_embeddings[\"Base\"].copy()\n",
    "\n",
    "    train_y = train_df[target_col].copy()\n",
    "    dev_y = dev_df[target_col].copy()\n",
    "    test_y = test_df[target_col].copy()\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = enc.fit_transform(train_y[train_y.notna()])\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = enc.transform(dev_y[dev_y.notna()])\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = enc.transform(test_y[test_y.notna()])\n",
    "\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "        display_name,\n",
    "        f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "        f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summarizer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luhn</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSA</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summarizer    Target  Dev F1  Test F1\n",
       "0       Luhn  Toxicity    0.88     0.88\n",
       "1        LSA  Toxicity    0.88     0.89\n",
       "2    LexRank  Toxicity    0.90     0.89\n",
       "3   TextRank  Toxicity    0.89     0.90"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = pd.DataFrame(columns=[\"Summarizer\", \"Target\", \"Dev F1\", \"Test F1\"])\n",
    "\n",
    "for summarizer in summarizer_models:\n",
    "    for target_col, display_name in [\n",
    "        (\"toxicity\", \"Toxicity\"),\n",
    "    ]:\n",
    "        train_X = np.concatenate(\n",
    "            (\n",
    "                train_sentence_embeddings[\"Base\"],\n",
    "                train_sentence_embeddings[str(summarizer)],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        dev_X = np.concatenate(\n",
    "            (dev_entence_embeddings[\"Base\"], dev_entence_embeddings[str(summarizer)]),\n",
    "            axis=1,\n",
    "        )\n",
    "        test_X = np.concatenate(\n",
    "            (\n",
    "                test_sentence_embeddings[\"Base\"],\n",
    "                test_sentence_embeddings[str(summarizer)],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        train_y = train_df[target_col]\n",
    "        dev_y = dev_df[target_col]\n",
    "        test_y = test_df[target_col]\n",
    "\n",
    "        train_X = train_X[train_y.notna()]\n",
    "        train_y = enc.fit_transform(train_y[train_y.notna()])\n",
    "\n",
    "        dev_X = dev_X[dev_y.notna()]\n",
    "        dev_y = enc.transform(dev_y[dev_y.notna()])\n",
    "\n",
    "        test_X = test_X[test_y.notna()]\n",
    "        test_y = enc.transform(test_y[test_y.notna()])\n",
    "\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred_dev_y = clf.predict(dev_X)\n",
    "        pred_test_y = clf.predict(test_X)\n",
    "\n",
    "        baseline_scores.loc[len(baseline_scores.index)] = [\n",
    "            str(summarizer),\n",
    "            display_name,\n",
    "            f1_score(dev_y, pred_dev_y, average=\"weighted\"),\n",
    "            f1_score(test_y, pred_test_y, average=\"weighted\"),\n",
    "        ]\n",
    "\n",
    "baseline_scores.round(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
