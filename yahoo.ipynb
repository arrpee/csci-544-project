{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import contractions\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from num2words import num2words\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv(\n",
    "    \"data/yahoo-news-annotated-comments-dataset/ydata-ynacc-v1_0_expert_annotations.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdid</th>\n",
       "      <th>commentindex</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>guid</th>\n",
       "      <th>commentid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>thumbs-up</th>\n",
       "      <th>thumbs-down</th>\n",
       "      <th>text</th>\n",
       "      <th>parentid</th>\n",
       "      <th>constructiveclass</th>\n",
       "      <th>sd_agreement</th>\n",
       "      <th>sd_type</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tone</th>\n",
       "      <th>commentagreement</th>\n",
       "      <th>topic</th>\n",
       "      <th>intendedaudience</th>\n",
       "      <th>persuasiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53971</td>\n",
       "      <td>2</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/</td>\n",
       "      <td>rjrPtwH5oVVuQnEXX3hf</td>\n",
       "      <td>00003n000000000000000000000000-ed2ae6d0-32ac-471a-b8b2-a718607ee376</td>\n",
       "      <td>1459917444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These things happen , Every job has its dangers.</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disagreement with commenter</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53971</td>\n",
       "      <td>0</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/</td>\n",
       "      <td>VaW6HEsuOFUAIBqjw1k~</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249</td>\n",
       "      <td>1459879464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sad to hear such a bad thing. Very dangerous job working on electricity. One questions though, why did they use a picture the Bates house from Psycho, on a Disney story? Or is that what the Paris Haunted Mansion/Phantom Manor looks like?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Broadcast message / general audience</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53971</td>\n",
       "      <td>1</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/</td>\n",
       "      <td>uwQePj970KaMZuW3~9Q9</td>\n",
       "      <td>00002n000000000000000000000000-1c30b878-b717-4e9a-9872-2ce2906ce783</td>\n",
       "      <td>1459881644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes..because too many houses in EU look like the original Disney Hunted House so it didn't look scary enough. Bates Motel looks more American and that notion alone scares everyone.</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Informative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135929</td>\n",
       "      <td>0</td>\n",
       "      <td>This Old Navy Ad Featuring an Interracial Family Is Being Attacked By Racist Trolls</td>\n",
       "      <td>http://mic.com/articles/142323/this-old-navy-ad-featuring-an-interracial-family-is-being-attacked-by-racist-trolls</td>\n",
       "      <td>fixyWJivQjEQtPLLVXsu</td>\n",
       "      <td>1462203719963-3eeffb02-faae-4b51-9174-704c57e6de37</td>\n",
       "      <td>1462203719</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I am frankly quite SICK of the phrase \"shoved down our throat\" You know what? Back in the newspaper and three network days you could say that...Now with 300 or more TV channels and an endless internet...You can keep your throat relatively clear of things you don't want...All you have to do is change the channel or click a link to something you DO like... So let's stop it with the \"shoved down our throat\" rhetoric.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not constructive</td>\n",
       "      <td>Agreement throughout</td>\n",
       "      <td>Off-topic/digression</td>\n",
       "      <td>negative</td>\n",
       "      <td>Mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Broadcast message / general audience</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135929</td>\n",
       "      <td>1</td>\n",
       "      <td>This Old Navy Ad Featuring an Interracial Family Is Being Attacked By Racist Trolls</td>\n",
       "      <td>http://mic.com/articles/142323/this-old-navy-ad-featuring-an-interracial-family-is-being-attacked-by-racist-trolls</td>\n",
       "      <td>_TDnK715vO5y0OzZz_n4</td>\n",
       "      <td>00002I000000000000000000000000-7ef2ac58-bd84-4027-88cf-b865bfe2f1f8</td>\n",
       "      <td>1462204643</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ya, I always wonder why the conservatives are on Yahoo!, whining about all the liberals, when they could be hanging out with their own kind, patting each other on the back, over at Faux News. Don't like what you see, switch the channel. No, they're a bit hypocritical about shoving things down peoples throats, and want to force they're way upon others.</td>\n",
       "      <td>1462203719963-3eeffb02-faae-4b51-9174-704c57e6de37</td>\n",
       "      <td>Not constructive</td>\n",
       "      <td>Agreement throughout</td>\n",
       "      <td>Off-topic/digression</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Agreement with commenter</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sdid  commentindex  \\\n",
       "0   53971             2   \n",
       "1   53971             0   \n",
       "2   53971             1   \n",
       "3  135929             0   \n",
       "4  135929             1   \n",
       "\n",
       "                                                                              headline  \\\n",
       "0                                      Disneyland Worker Found Dead in Haunted Mansion   \n",
       "1                                      Disneyland Worker Found Dead in Haunted Mansion   \n",
       "2                                      Disneyland Worker Found Dead in Haunted Mansion   \n",
       "3  This Old Navy Ad Featuring an Interracial Family Is Being Attacked By Racist Trolls   \n",
       "4  This Old Navy Ad Featuring an Interracial Family Is Being Attacked By Racist Trolls   \n",
       "\n",
       "                                                                                                                  url  \\\n",
       "0                           http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/   \n",
       "1                           http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/   \n",
       "2                           http://www.cosmopolitan.com/lifestyle/news/a56215/disneyland-paris-haunted-mansion-death/   \n",
       "3  http://mic.com/articles/142323/this-old-navy-ad-featuring-an-interracial-family-is-being-attacked-by-racist-trolls   \n",
       "4  http://mic.com/articles/142323/this-old-navy-ad-featuring-an-interracial-family-is-being-attacked-by-racist-trolls   \n",
       "\n",
       "                   guid  \\\n",
       "0  rjrPtwH5oVVuQnEXX3hf   \n",
       "1  VaW6HEsuOFUAIBqjw1k~   \n",
       "2  uwQePj970KaMZuW3~9Q9   \n",
       "3  fixyWJivQjEQtPLLVXsu   \n",
       "4  _TDnK715vO5y0OzZz_n4   \n",
       "\n",
       "                                                             commentid  \\\n",
       "0  00003n000000000000000000000000-ed2ae6d0-32ac-471a-b8b2-a718607ee376   \n",
       "1                   1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249   \n",
       "2  00002n000000000000000000000000-1c30b878-b717-4e9a-9872-2ce2906ce783   \n",
       "3                   1462203719963-3eeffb02-faae-4b51-9174-704c57e6de37   \n",
       "4  00002I000000000000000000000000-7ef2ac58-bd84-4027-88cf-b865bfe2f1f8   \n",
       "\n",
       "    timestamp  thumbs-up  thumbs-down  \\\n",
       "0  1459917444        NaN          NaN   \n",
       "1  1459879464        1.0          NaN   \n",
       "2  1459881644        NaN          NaN   \n",
       "3  1462203719       18.0          3.0   \n",
       "4  1462204643        7.0          2.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                   These things happen , Every job has its dangers.   \n",
       "1                                                                                                                                                                                      Sad to hear such a bad thing. Very dangerous job working on electricity. One questions though, why did they use a picture the Bates house from Psycho, on a Disney story? Or is that what the Paris Haunted Mansion/Phantom Manor looks like?   \n",
       "2                                                                                                                                                                                                                                               Yes..because too many houses in EU look like the original Disney Hunted House so it didn't look scary enough. Bates Motel looks more American and that notion alone scares everyone.   \n",
       "3  I am frankly quite SICK of the phrase \"shoved down our throat\" You know what? Back in the newspaper and three network days you could say that...Now with 300 or more TV channels and an endless internet...You can keep your throat relatively clear of things you don't want...All you have to do is change the channel or click a link to something you DO like... So let's stop it with the \"shoved down our throat\" rhetoric.   \n",
       "4                                                                  Ya, I always wonder why the conservatives are on Yahoo!, whining about all the liberals, when they could be hanging out with their own kind, patting each other on the back, over at Faux News. Don't like what you see, switch the channel. No, they're a bit hypocritical about shoving things down peoples throats, and want to force they're way upon others.   \n",
       "\n",
       "                                             parentid constructiveclass  \\\n",
       "0  1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249      Constructive   \n",
       "1                                                 NaN      Constructive   \n",
       "2  1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b4249      Constructive   \n",
       "3                                                 NaN  Not constructive   \n",
       "4  1462203719963-3eeffb02-faae-4b51-9174-704c57e6de37  Not constructive   \n",
       "\n",
       "           sd_agreement               sd_type sentiment         tone  \\\n",
       "0                   NaN   Positive/respectful  negative          NaN   \n",
       "1                   NaN   Positive/respectful     mixed          NaN   \n",
       "2                   NaN   Positive/respectful   neutral  Informative   \n",
       "3  Agreement throughout  Off-topic/digression  negative         Mean   \n",
       "4  Agreement throughout  Off-topic/digression   neutral    Sarcastic   \n",
       "\n",
       "              commentagreement                   topic  \\\n",
       "0  Disagreement with commenter  Off-topic with article   \n",
       "1                          NaN  Off-topic with article   \n",
       "2                          NaN  Off-topic with article   \n",
       "3                          NaN  Off-topic with article   \n",
       "4     Agreement with commenter  Off-topic with article   \n",
       "\n",
       "                       intendedaudience  persuasiveness  \n",
       "0         Reply to a specific commenter  Not persuasive  \n",
       "1  Broadcast message / general audience  Not persuasive  \n",
       "2         Reply to a specific commenter  Not persuasive  \n",
       "3  Broadcast message / general audience      Persuasive  \n",
       "4         Reply to a specific commenter  Not persuasive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_words(text: str) -> str:\n",
    "    t = text.split()\n",
    "    for ind, word in enumerate(t):\n",
    "        if all(c.isdigit() for c in word):\n",
    "            t[ind] = num2words(word)\n",
    "        elif (\n",
    "            len(word) > 2\n",
    "            and all(c.isdigit() for c in word[:-2])\n",
    "            and word[-2:] in [\"st\", \"nd\", \"rd\", \"th\"]\n",
    "        ):\n",
    "            t[ind] = num2words(int(word[:-2]), to=\"ordinal\")\n",
    "\n",
    "    return \" \".join(t)\n",
    "\n",
    "\n",
    "def get_comment_thread(row: pd.Series) -> str:\n",
    "    if not row[\"text\"]:\n",
    "        return \"\"\n",
    "    if row[\"text\"][-1] not in string.punctuation:\n",
    "        row[\"text\"] += \".\"\n",
    "\n",
    "    if row[\"commentindex\"] != 0:\n",
    "        parent_df = yahoo_df[yahoo_df.commentid == row[\"parentid\"]]\n",
    "        if parent_df.shape[0] == 0:\n",
    "            return row[\"text\"]\n",
    "        else:\n",
    "            return f\"{parent_df.iloc[0].thread} {row['text']}\"\n",
    "    else:\n",
    "        return row[\"text\"]\n",
    "\n",
    "\n",
    "yahoo_df[\"text\"] = (\n",
    "    yahoo_df[\"text\"]\n",
    "    .str.replace(r\"[^\\w\\s]+\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .apply(lambda x: contractions.fix(x, slang=False))\n",
    "    .apply(numbers_to_words)\n",
    "    .astype(str)\n",
    ")\n",
    "yahoo_df = yahoo_df.sort_values(by=[\"commentindex\"])\n",
    "yahoo_df[\"thread\"] = \"\"\n",
    "for index, row in yahoo_df.iterrows():\n",
    "    yahoo_df.at[index, \"thread\"] = get_comment_thread(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "NUM_SENTENCES = 3\n",
    "\n",
    "tokenizer = Tokenizer(LANGUAGE)\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "summarizer = LuhnSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "\n",
    "def summarize_thread(row: pd.Series) -> str:\n",
    "    if not row[\"thread\"]:\n",
    "        return \"\"\n",
    "    parser = PlaintextParser.from_string(row[\"thread\"], tokenizer)\n",
    "    return \"\".join([x._text for x in summarizer(parser.document, NUM_SENTENCES)])\n",
    "\n",
    "\n",
    "yahoo_df[\"summary\"] = yahoo_df.apply(summarize_thread, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"data/yahoo-news-annotated-comments-dataset/ydata-ynacc-v1_0_train-ids.txt\"\n",
    ") as f:\n",
    "    train_ids = [int(x) for x in f.read().splitlines()]\n",
    "\n",
    "with open(\n",
    "    \"data/yahoo-news-annotated-comments-dataset/ydata-ynacc-v1_0_dev-ids.txt\"\n",
    ") as f:\n",
    "    dev_ids = [int(x) for x in f.read().splitlines()]\n",
    "\n",
    "with open(\n",
    "    \"data/yahoo-news-annotated-comments-dataset/ydata-ynacc-v1_0_test-ids.txt\"\n",
    ") as f:\n",
    "    test_ids = [int(x) for x in f.read().splitlines()]\n",
    "\n",
    "train_df = yahoo_df[yahoo_df[\"sdid\"].isin(train_ids)]\n",
    "dev_df = yahoo_df[yahoo_df[\"sdid\"].isin(dev_ids)]\n",
    "test_df = yahoo_df[yahoo_df[\"sdid\"].isin(test_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        train  dev  test\n",
      "sentiment commentindex                  \n",
      "mixed     [0, 3)         1340  107    86\n",
      "          [3, 6)         1006   88    35\n",
      "          [6, 9)          507   27    24\n",
      "          [9, 12)         189    4     5\n",
      "          [12, 15)         67    1     0\n",
      "          [15, 18)          6    0     0\n",
      "negative  [0, 3)         4764  388   340\n",
      "          [3, 6)         3541  277   233\n",
      "          [6, 9)         1407   53    94\n",
      "          [9, 12)         544   17    13\n",
      "          [12, 15)        167    0     0\n",
      "          [15, 18)         11    0     0\n",
      "neutral   [0, 3)         2278  208   102\n",
      "          [3, 6)         1873  155    81\n",
      "          [6, 9)          724   52    24\n",
      "          [9, 12)         281   12     2\n",
      "          [12, 15)         90    0     0\n",
      "          [15, 18)          5    0     0\n",
      "positive  [0, 3)          685   47    56\n",
      "          [3, 6)          468   38    32\n",
      "          [6, 9)          171   15     6\n",
      "          [9, 12)          48    2     4\n",
      "          [12, 15)         15    0     0\n",
      "          [15, 18)          0    0     0\n"
     ]
    }
   ],
   "source": [
    "temp_df = yahoo_df.copy(deep=True)\n",
    "temp_df[\"train\"] = temp_df[\"sdid\"].isin(train_ids)\n",
    "temp_df[\"dev\"] = temp_df[\"sdid\"].isin(dev_ids)\n",
    "temp_df[\"test\"] = temp_df[\"sdid\"].isin(test_ids)\n",
    "\n",
    "with pd.option_context(\n",
    "    \"display.max_rows\",\n",
    "    None,\n",
    "):\n",
    "    print(\n",
    "        temp_df.groupby(\n",
    "            [\n",
    "                \"sentiment\",\n",
    "                pd.cut(\n",
    "                    temp_df.commentindex,\n",
    "                    [0, 3, 6, 9, 12, 15, 18],\n",
    "                    include_lowest=True,\n",
    "                    right=False,\n",
    "                ),\n",
    "            ]\n",
    "        )[[\"train\", \"dev\", \"test\"]].sum()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persuasiveness : \n",
      "0.7257473091130282\n",
      "0.7521520819431557\n",
      "intendedaudience : \n",
      "0.5646423242721982\n",
      "0.6526634767180163\n",
      "topic : \n",
      "0.5973614756428787\n",
      "0.675730583993962\n",
      "tone : \n",
      "0.2562503964198996\n",
      "0.3662351613881465\n",
      "constructiveclass : \n",
      "0.5726089898169763\n",
      "0.5843001461585312\n"
     ]
    }
   ],
   "source": [
    "def get_average_w2v_vector(row):\n",
    "    words = row[\"text\"].split()\n",
    "    thread_words = row[\"thread\"].split()\n",
    "\n",
    "    avg_text_w2v = np.sum([model[w] for w in words if w in model], axis=0) / (\n",
    "        len(words) if words else 1\n",
    "    )\n",
    "\n",
    "    if avg_text_w2v.shape != (300,):\n",
    "        avg_text_w2v = np.zeros((300,))\n",
    "\n",
    "    avg_thread_w2v = np.sum([model[w] for w in thread_words if w in model], axis=0) / (\n",
    "        len(thread_words) if thread_words else 1\n",
    "    )\n",
    "\n",
    "    if avg_thread_w2v.shape != (300,):\n",
    "        avg_thread_w2v = np.zeros((300,))\n",
    "\n",
    "    embedding = np.concatenate((avg_text_w2v, avg_thread_w2v), axis=None)\n",
    "    return embedding\n",
    "\n",
    "f1_scores = pd.DataFrame(columns=['Target Column', 'Dev Dataset F1', 'Test Dataset F1'])\n",
    "\n",
    "for target_col in [\n",
    "    \"persuasiveness\",\n",
    "    \"intendedaudience\",\n",
    "    \"topic\",\n",
    "    \"tone\",\n",
    "    \"constructiveclass\",\n",
    "]:\n",
    "\n",
    "    train_X = train_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    dev_X = dev_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "    test_X = test_df.apply(\n",
    "        lambda x: get_average_w2v_vector(x), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    train_y = train_df[target_col]\n",
    "    dev_y = dev_df[target_col]\n",
    "    test_y = test_df[target_col]\n",
    "\n",
    "    train_X = train_X[train_y.notna()]\n",
    "    train_y = train_y[train_y.notna()]\n",
    "\n",
    "    dev_X = dev_X[dev_y.notna()]\n",
    "    dev_y = dev_y[dev_y.notna()]\n",
    "\n",
    "    test_X = test_X[test_y.notna()]\n",
    "    test_y = test_y[test_y.notna()]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    pred_dev_y = clf.predict(dev_X)\n",
    "    pred_test_y = clf.predict(test_X)\n",
    "\n",
    "    print(f\"{target_col} : \")\n",
    "    print(f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0))\n",
    "    print(f1_score(test_y, pred_test_y, average='weighted', zero_division=0))\n",
    "    f1_scores.loc[len(f1_scores.index)] = [target_col, f1_score(dev_y, pred_dev_y, average='weighted', zero_division=0), f1_score(test_y, pred_test_y, average='weighted', zero_division=0)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/csci-544-project/venv/lib/python3.10/site-packages/pandas/compat/_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jinja2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(f1_scores\u001b[39m.\u001b[39;49mstyle\u001b[39m.\u001b[39mto_latex(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, float_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Projects/csci-544-project/venv/lib/python3.10/site-packages/pandas/core/frame.py:1263\u001b[0m, in \u001b[0;36mDataFrame.style\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstyle\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Styler:\n\u001b[1;32m   1253\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m \u001b[39m    Returns a Styler object.\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[39m        data with HTML and CSS.\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle\u001b[39;00m \u001b[39mimport\u001b[39;00m Styler\n\u001b[1;32m   1265\u001b[0m     \u001b[39mreturn\u001b[39;00m Styler(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/csci-544-project/venv/lib/python3.10/site-packages/pandas/io/formats/style.py:56\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mshared_docs\u001b[39;00m \u001b[39mimport\u001b[39;00m _shared_docs\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformat\u001b[39;00m \u001b[39mimport\u001b[39;00m save_to_buffer\n\u001b[0;32m---> 56\u001b[0m jinja2 \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mjinja2\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDataFrame.style requires jinja2.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle_render\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     CSSProperties,\n\u001b[1;32m     60\u001b[0m     CSSStyles,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     refactor_levels,\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/csci-544-project/venv/lib/python3.10/site-packages/pandas/compat/_optional.py:144\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    145\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2."
     ]
    }
   ],
   "source": [
    "print(f1_scores.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fce3f33274e5da354ee51a1f13b514a1195d394c6831008ceaf2ec8369c9243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
